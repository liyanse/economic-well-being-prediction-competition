{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24238424",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb7cf673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\shee\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\shee\\anaconda3\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\shee\\anaconda3\\lib\\site-packages (from lightgbm) (1.20.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\shee\\anaconda3\\lib\\site-packages (from lightgbm) (1.7.1)\n",
      "Requirement already satisfied: wheel in c:\\users\\shee\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shee\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\shee\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "#Ensemble boositng works best with lightgbm, the gbm means gradient boosting model, \n",
    "#Remember to make notes on this when the competition ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38aea856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold,StratifiedKFold ,GroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c02b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python, unlike Java, favors me when it comes to functions, so we'll create on that collects data from both sets(train and test)\n",
    "def get_processed_data(train_path,test_path) :\n",
    "\n",
    "    #Import the data\n",
    "    \n",
    "    train = pd.read_csv(r'C:\\Users\\shee\\Desktop\\Umoja Hack Zindi\\economic-well-being-prediction-competition\\Train.csv')\n",
    "    test  = pd.read_csv(r'C:\\Users\\shee\\Desktop\\Umoja Hack Zindi\\economic-well-being-prediction-competition\\Test.csv')\n",
    "\n",
    "    data = pd.concat([train, test]).reset_index(drop=True)\n",
    "    \n",
    "#These are the unique columsn to predict the wealth\n",
    "    col = ['country', 'year', 'urban_or_rural']\n",
    "    \n",
    "    ## Count of unique features\n",
    "    for i in col:\n",
    "        data['count_'+i] = data[i].map(data[i].value_counts())\n",
    "        \n",
    "    ## Combination features\n",
    "    data['all_ghsl'] = data['ghsl_built_1975_to_1990']+data['ghsl_built_pre_1975']+data['ghsl_built_1990_to_2000']+data['ghsl_built_2000_to_2014']\n",
    "    data['all_landcover_fraction'] = data['landcover_crops_fraction']+data['landcover_urban_fraction']\n",
    "    data['all_waters'] = data['landcover_water_permanent_10km_fraction'] + data['landcover_water_seasonal_10km_fraction']\n",
    "    \n",
    "    # get train , test\n",
    "    train = data[data['ID'].isin(train['ID'].values)]\n",
    "    test = data[~data['ID'].isin(train['ID'].values)]\n",
    "    #Don't forget our unique columsn\n",
    "    features = [x for x in train.columns if x not in \n",
    "                ['ID','country','urban_or_rural','Target','year']]\n",
    "    return train , test , features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49f8596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 'Train.csv' ; test_data = 'Test.csv'\n",
    "train , test , features = get_processed_data(train_path,test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bbb8885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will be our magic model. I'm hoping the predictions wouldn't be as worse than the one's I've handed in so far.\n",
    "def get_model(Name='lgbm') :\n",
    "    if Name=='lgbm' :\n",
    "      return LGBMRegressor(**{'objective' :'regression','boosting_type' : 'gbdt','metric': 'rmse' ,\n",
    "                              'learning_rate' : 0.05,'num_iterations': 1500,'max_depth' :4 ,'num_leaves' : 150,\n",
    "                              'max_bins': 85,'min_data_in_leaf':30,'reg_lambda' :75})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eddfdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "Fold 1 Val score: 0.08752408256678368\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "Fold 2 Val score: 0.09237492907308259\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "Fold 3 Val score: 0.08227360283659732\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "Fold 4 Val score: 0.08561543523309978\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "Fold 5 Val score: 0.08586873090583692\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "Fold 6 Val score: 0.08496675253229934\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "Fold 7 Val score: 0.0878105261630131\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "Fold 8 Val score: 0.08478606391518649\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "Fold 9 Val score: 0.08517126624098573\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "Fold 10 Val score: 0.08578828806329575\n",
      "-- -- -- ---- -- -- ---- -- -- ---- -- -- --\n",
      "\n",
      "######### ^^^^^^^^^^ #########\n",
      "0.08625469124559959\n"
     ]
    }
   ],
   "source": [
    "Model_Name = \"lgbm\"\n",
    "\n",
    "X = train[features]\n",
    "y = train['Target']\n",
    "test_ = test[features]\n",
    "\n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=2021)\n",
    "oofs  = np.zeros((len(X)))\n",
    "test_predictions = np.zeros((len(test)))\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    \n",
    "    X_trn, y_trn = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "\n",
    "    clf = get_model(Name=Model_Name)\n",
    "    clf.fit(X_trn, y_trn, eval_set = [(X_val, y_val)],\n",
    "            verbose = 0, early_stopping_rounds = 50)\n",
    "    \n",
    "    vp = clf.predict(X_val)\n",
    "    oofs[val_idx] = vp\n",
    "    val_score = mean_squared_error((vp), (y_val),squared=False)\n",
    "    print(4*'-- -- -- --')\n",
    "    print(f'Fold {fold_+1} Val score: {val_score}')\n",
    "    print(4*'-- -- -- --')\n",
    "    \n",
    "    tp = clf.predict(test_)\n",
    "    test_predictions += tp / folds.n_splits\n",
    "\n",
    "print()\n",
    "print(3*'###',10*\"^\",3*'###')\n",
    "print(mean_squared_error(y, oofs,squared=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fee2d15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['Target'] = np.clip(test_predictions, 0.141000, 0.808657)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0f9ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(r'C:\\Users\\shee\\Desktop\\Umoja Hack Zindi\\economic-well-being-prediction-competition\\first_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0261085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4bd4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
